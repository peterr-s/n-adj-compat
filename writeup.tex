Task

The goal of this project is to determine the semantic compatibility of a noun/adjective pair on the basis of their word embeddings. The model is a feed-forward neural network trained on pairs that were or were not found in a large corpus.


Motivation

The motivation for this type of program is primarily its usefulness as a filtering step for compositional embedding generation. A compositional embedding over words that are syntactically incompatible is at best meaningless, and at worst misleading, possibly colliding with the embedding of an actual word to which the pair has no intuitive or useful relationsihp. This also means that when training these compositional models such a filter might potentially increase accuracy by allowing the model to focus on those compositions which actually do make sense.

Another use for this functionality is in parsing, since a dependency will not exist in a meaningful sentence, i.e. any of most sentences encountered in real parsing tasks, between a noun and a semantically incompatible adjective. This means that these arcs can be ruled out, improving performance.


Preprocessing

The inputs to the neural network are Word2Vec embeddings trained over the entire dataset. A window size of 10 ensures that the embeddings carry more semantic than syntactic information, and a minimum count of 50 ensures that all the embeddings used have been trained well enough to be reasonably accurate representations. I chose an embedding dimensionality of 300 to ensure that the network has as fine-grained information to work with as possible.

The ConLL data is searched for dependencies between nouns of any type and adjectives of any type. Any pairs for which an embedding is not found for either component are discarded since they will be of no use for training. Because any pair found in the corpus can be assumed to be valid, the positive samples on which the model is trained are simply all pairs which occur in the corpus on which it can be trained, i.e. all those for which embeddings could be generated. This means that the minimum count for the embedding model has a further consequence beyond ensuring validity of the embeddings: the model will not attempt to learn based on rare words which might have strange or simply incompletely represented compatibility properties. Because the list is not deduplicated, the model learns primarily from pairs where the compatiblity is well-established.

Of course, it does not make sense to train only on positive samples. Negative samples are generated first by random sampling, but then filtered against not only pairs that did occur, but those which are embedding-wise similar. In order to avoid doing a quadratic number of searches depending on the number of similar embeddings taken into account, I make a quadratic number of entries in a Bloom filter, which is of course much faster while still being memory efficient. The filter is designed to have a false positive rate of at most 5%, though in reality this should be even lower since the element count is estimated directly from the number of positive samples and the filter does not need additional space for duplicate elements. The process is further sped up by keeping the neighbor lists in a hash map once they have been looked up, which costs memory at preprocessing time but allows it to be freed for training.

Each negative sample is generated and then tested against the Bloom filter, then scrapped and regenerated if it is found. This allows precise control over the number of negative samples. In order to maintain a balanced training set, I fixed this to the number of positive samples.


